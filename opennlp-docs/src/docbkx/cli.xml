<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd"[
]>
<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->


<!-- ## Warning ## this content is autogenerated! Please fix issues in to opennlp-tools/src/main/java/opennlp/tools/cmdline/GenerateManualTool.java 
   and execute the following command in opennlp-tool folder to update this file: 

      mvn -e -q exec:java "-Dexec.mainClass=opennlp.tools.cmdline.GenerateManualTool" "-Dexec.args=../opennlp-docs/src/docbkx/cli.xml"
-->

<chapter id='tools.cli'>

<title>The Command Line Interface</title>

<para>This section details the available tools and parameters of the Command Line Interface. For a introduction in its usage please refer to <xref linkend='intro.cli'/>.  </para>

<section id='tools.cli.doccat'>

<title>Doccat</title>

<section id='tools.cli.doccat.Doccat'>

<title>Doccat</title>

<para>Learnable document categorizer</para>

<screen>
<![CDATA[
Usage: opennlp Doccat model < documents

]]>
</screen> 
</section>

<section id='tools.cli.doccat.DoccatTrainer'>

<title>DoccatTrainer</title>

<para>Trainer for the learnable document categorizer</para>

<screen>
<![CDATA[
Usage: opennlp DoccatTrainer[.leipzig] [-factory factoryName] [-tokenizer tokenizer] [-featureGenerators fg] 
        [-params paramsFile] -lang language -model modelFile -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of DoccatFactory where to get implementation and resources.
	-tokenizer tokenizer
		Tokenizer implementation. WhitespaceTokenizer is used if not specified.
	-featureGenerators fg
		Comma separated feature generator classes. Bag of words is used if not specified.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='1' valign='middle'>leipzig</entry>
<entry>sentencesDir</entry>
<entry>sentencesDir</entry>
<entry>No</entry>
<entry>Dir with Leipig sentences to be used</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.doccat.DoccatEvaluator'>

<title>DoccatEvaluator</title>

<para>Measures the performance of the Doccat model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp DoccatEvaluator[.leipzig] [-misclassified true|false] -model model [-reportOutputFile 
        outputFile] -data sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='1' valign='middle'>leipzig</entry>
<entry>sentencesDir</entry>
<entry>sentencesDir</entry>
<entry>No</entry>
<entry>Dir with Leipig sentences to be used</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.doccat.DoccatCrossValidator'>

<title>DoccatCrossValidator</title>

<para>K-fold cross validator for the learnable Document Categorizer</para>

<screen>
<![CDATA[
Usage: opennlp DoccatCrossValidator[.leipzig] [-folds num] [-misclassified true|false] [-factory factoryName] 
        [-tokenizer tokenizer] [-featureGenerators fg] [-params paramsFile] -lang language [-reportOutputFile 
        outputFile] -data sampleData [-encoding charsetName] 
Arguments description:
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-factory factoryName
		A sub-class of DoccatFactory where to get implementation and resources.
	-tokenizer tokenizer
		Tokenizer implementation. WhitespaceTokenizer is used if not specified.
	-featureGenerators fg
		Comma separated feature generator classes. Bag of words is used if not specified.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='1' valign='middle'>leipzig</entry>
<entry>sentencesDir</entry>
<entry>sentencesDir</entry>
<entry>No</entry>
<entry>Dir with Leipig sentences to be used</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.doccat.DoccatConverter'>

<title>DoccatConverter</title>

<para>Converts leipzig data format to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp DoccatConverter help|leipzig [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='1' valign='middle'>leipzig</entry>
<entry>sentencesDir</entry>
<entry>sentencesDir</entry>
<entry>No</entry>
<entry>Dir with Leipig sentences to be used</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

</section>

<section id='tools.cli.dictionary'>

<title>Dictionary</title>

<section id='tools.cli.dictionary.DictionaryBuilder'>

<title>DictionaryBuilder</title>

<para>Builds a new dictionary</para>

<screen>
<![CDATA[
Usage: opennlp DictionaryBuilder -outputFile out -inputFile in [-encoding charsetName]

Arguments description:
	-outputFile out
		The dictionary file.
	-inputFile in
		Plain file with one entry per line
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
</section>

</section>

<section id='tools.cli.tokenizer'>

<title>Tokenizer</title>

<section id='tools.cli.tokenizer.SimpleTokenizer'>

<title>SimpleTokenizer</title>

<para>Character class tokenizer</para>

<screen>
<![CDATA[
Usage: opennlp SimpleTokenizer < sentences

]]>
</screen> 
</section>

<section id='tools.cli.tokenizer.TokenizerME'>

<title>TokenizerME</title>

<para>Learnable tokenizer</para>

<screen>
<![CDATA[
Usage: opennlp TokenizerME model < sentences

]]>
</screen> 
</section>

<section id='tools.cli.tokenizer.TokenizerTrainer'>

<title>TokenizerTrainer</title>

<para>Trainer for the learnable tokenizer</para>

<screen>
<![CDATA[
Usage: opennlp TokenizerTrainer[.ad|.pos|.conllx|.namefinder|.parse] [-factory factoryName] [-abbDict path] 
        [-alphaNumOpt isAlphaNumOpt] [-params paramsFile] -lang language -model modelFile -data sampleData 
        [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of TokenizerFactory where to get implementation and resources.
	-abbDict path
		abbreviation dictionary in XML format.
	-alphaNumOpt isAlphaNumOpt
		Optimization flag to skip alpha numeric tokens for further tokenization
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.tokenizer.TokenizerMEEvaluator'>

<title>TokenizerMEEvaluator</title>

<para>Evaluator for the learnable tokenizer</para>

<screen>
<![CDATA[
Usage: opennlp TokenizerMEEvaluator[.ad|.pos|.conllx|.namefinder|.parse] [-misclassified true|false] -model 
        model -data sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.tokenizer.TokenizerCrossValidator'>

<title>TokenizerCrossValidator</title>

<para>K-fold cross validator for the learnable tokenizer</para>

<screen>
<![CDATA[
Usage: opennlp TokenizerCrossValidator[.ad|.pos|.conllx|.namefinder|.parse] [-folds num] [-misclassified 
        true|false] [-factory factoryName] [-abbDict path] [-alphaNumOpt isAlphaNumOpt] [-params paramsFile] 
        -lang language -data sampleData [-encoding charsetName] 
Arguments description:
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-factory factoryName
		A sub-class of TokenizerFactory where to get implementation and resources.
	-abbDict path
		abbreviation dictionary in XML format.
	-alphaNumOpt isAlphaNumOpt
		Optimization flag to skip alpha numeric tokens for further tokenization
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.tokenizer.TokenizerConverter'>

<title>TokenizerConverter</title>

<para>Converts foreign data formats (ad,pos,conllx,namefinder,parse) to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp TokenizerConverter help|ad|pos|conllx|namefinder|parse [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.tokenizer.DictionaryDetokenizer'>

<title>DictionaryDetokenizer</title>

<para></para>

<screen>
<![CDATA[
Usage: opennlp DictionaryDetokenizer detokenizerDictionary

]]>
</screen> 
</section>

</section>

<section id='tools.cli.sentdetect'>

<title>Sentdetect</title>

<section id='tools.cli.sentdetect.SentenceDetector'>

<title>SentenceDetector</title>

<para>Learnable sentence detector</para>

<screen>
<![CDATA[
Usage: opennlp SentenceDetector model < sentences

]]>
</screen> 
</section>

<section id='tools.cli.sentdetect.SentenceDetectorTrainer'>

<title>SentenceDetectorTrainer</title>

<para>Trainer for the learnable sentence detector</para>

<screen>
<![CDATA[
Usage: opennlp SentenceDetectorTrainer[.ad|.pos|.conllx|.namefinder|.parse|.moses|.letsmt] [-factory 
        factoryName] [-eosChars string] [-abbDict path] [-params paramsFile] -lang language -model modelFile 
        -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of SentenceDetectorFactory where to get implementation and resources.
	-eosChars string
		EOS characters.
	-abbDict path
		abbreviation dictionary in XML format.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>includeTitles</entry>
<entry>includeTitles</entry>
<entry>Yes</entry>
<entry>If true will include sentences marked as headlines.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>moses</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>letsmt</entry>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>Yes</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.sentdetect.SentenceDetectorEvaluator'>

<title>SentenceDetectorEvaluator</title>

<para>Evaluator for the learnable sentence detector</para>

<screen>
<![CDATA[
Usage: opennlp SentenceDetectorEvaluator[.ad|.pos|.conllx|.namefinder|.parse|.moses|.letsmt] [-misclassified 
        true|false] -model model -data sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>includeTitles</entry>
<entry>includeTitles</entry>
<entry>Yes</entry>
<entry>If true will include sentences marked as headlines.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>moses</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>letsmt</entry>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>Yes</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.sentdetect.SentenceDetectorCrossValidator'>

<title>SentenceDetectorCrossValidator</title>

<para>K-fold cross validator for the learnable sentence detector</para>

<screen>
<![CDATA[
Usage: opennlp SentenceDetectorCrossValidator[.ad|.pos|.conllx|.namefinder|.parse|.moses|.letsmt] [-factory 
        factoryName] [-eosChars string] [-abbDict path] [-params paramsFile] -lang language [-folds num] 
        [-misclassified true|false] -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of SentenceDetectorFactory where to get implementation and resources.
	-eosChars string
		EOS characters.
	-abbDict path
		abbreviation dictionary in XML format.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>includeTitles</entry>
<entry>includeTitles</entry>
<entry>Yes</entry>
<entry>If true will include sentences marked as headlines.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>moses</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>letsmt</entry>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>Yes</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.sentdetect.SentenceDetectorConverter'>

<title>SentenceDetectorConverter</title>

<para>Converts foreign data formats (ad,pos,conllx,namefinder,parse,moses,letsmt) to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp SentenceDetectorConverter help|ad|pos|conllx|namefinder|parse|moses|letsmt [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>includeTitles</entry>
<entry>includeTitles</entry>
<entry>Yes</entry>
<entry>If true will include sentences marked as headlines.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>pos</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>namefinder</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>No</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>moses</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>letsmt</entry>
<entry>detokenizer</entry>
<entry>dictionary</entry>
<entry>Yes</entry>
<entry>Specifies the file with detokenizer dictionary.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

</section>

<section id='tools.cli.namefind'>

<title>Namefind</title>

<section id='tools.cli.namefind.TokenNameFinder'>

<title>TokenNameFinder</title>

<para>Learnable name finder</para>

<screen>
<![CDATA[
Usage: opennlp TokenNameFinder model1 model2 ... modelN < sentences

]]>
</screen> 
</section>

<section id='tools.cli.namefind.TokenNameFinderTrainer'>

<title>TokenNameFinderTrainer</title>

<para>Trainer for the learnable name finder</para>

<screen>
<![CDATA[
Usage: opennlp TokenNameFinderTrainer[.evalita|.ad|.conll03|.bionlp2004|.conll02|.muc6|.ontonotes|.brat] 
        [-factory factoryName] [-resources resourcesDir] [-type modelType] [-featuregen featuregenFile] 
        [-nameTypes types] [-sequenceCodec codec] [-params paramsFile] -lang language -model modelFile -data 
        sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of TokenNameFinderFactory
	-resources resourcesDir
		The resources directory
	-type modelType
		The type of the token name finder model
	-featuregen featuregenFile
		The feature generator descriptor file
	-nameTypes types
		name types to use for training
	-sequenceCodec codec
		sequence codec used to code name spans
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>evalita</entry>
<entry>lang</entry>
<entry>it</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,gpe</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll03</entry>
<entry>lang</entry>
<entry>en|de</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>bionlp2004</entry>
<entry>types</entry>
<entry>DNA,protein,cell_type,cell_line,RNA</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll02</entry>
<entry>lang</entry>
<entry>es|nl</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>muc6</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='5' valign='middle'>brat</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>ruleBasedTokenizer</entry>
<entry>name</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>annotationConfig</entry>
<entry>annConfFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>bratDataDir</entry>
<entry>bratDataDir</entry>
<entry>No</entry>
<entry>Location of brat data dir</entry>
</row>
<row>
<entry>recursive</entry>
<entry>value</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>sentenceDetectorModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.namefind.TokenNameFinderEvaluator'>

<title>TokenNameFinderEvaluator</title>

<para>Measures the performance of the NameFinder model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp TokenNameFinderEvaluator[.evalita|.ad|.conll03|.bionlp2004|.conll02|.muc6|.ontonotes|.brat] 
        [-nameTypes types] [-misclassified true|false] -model model [-detailedF true|false] 
        [-reportOutputFile outputFile] -data sampleData [-encoding charsetName] 
Arguments description:
	-nameTypes types
		name types to use for evaluation
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-detailedF true|false
		if true will print detailed FMeasure results.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>evalita</entry>
<entry>lang</entry>
<entry>it</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,gpe</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll03</entry>
<entry>lang</entry>
<entry>en|de</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>bionlp2004</entry>
<entry>types</entry>
<entry>DNA,protein,cell_type,cell_line,RNA</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll02</entry>
<entry>lang</entry>
<entry>es|nl</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>muc6</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='5' valign='middle'>brat</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>ruleBasedTokenizer</entry>
<entry>name</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>annotationConfig</entry>
<entry>annConfFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>bratDataDir</entry>
<entry>bratDataDir</entry>
<entry>No</entry>
<entry>Location of brat data dir</entry>
</row>
<row>
<entry>recursive</entry>
<entry>value</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>sentenceDetectorModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.namefind.TokenNameFinderCrossValidator'>

<title>TokenNameFinderCrossValidator</title>

<para>K-fold cross validator for the learnable Name Finder</para>

<screen>
<![CDATA[
Usage: opennlp 
        TokenNameFinderCrossValidator[.evalita|.ad|.conll03|.bionlp2004|.conll02|.muc6|.ontonotes|.brat] 
        [-factory factoryName] [-resources resourcesDir] [-type modelType] [-featuregen featuregenFile] 
        [-nameTypes types] [-sequenceCodec codec] [-params paramsFile] -lang language [-folds num] 
        [-misclassified true|false] [-detailedF true|false] [-reportOutputFile outputFile] -data sampleData 
        [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of TokenNameFinderFactory
	-resources resourcesDir
		The resources directory
	-type modelType
		The type of the token name finder model
	-featuregen featuregenFile
		The feature generator descriptor file
	-nameTypes types
		name types to use for training
	-sequenceCodec codec
		sequence codec used to code name spans
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-detailedF true|false
		if true will print detailed FMeasure results.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>evalita</entry>
<entry>lang</entry>
<entry>it</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,gpe</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll03</entry>
<entry>lang</entry>
<entry>en|de</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>bionlp2004</entry>
<entry>types</entry>
<entry>DNA,protein,cell_type,cell_line,RNA</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll02</entry>
<entry>lang</entry>
<entry>es|nl</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>muc6</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='5' valign='middle'>brat</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>ruleBasedTokenizer</entry>
<entry>name</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>annotationConfig</entry>
<entry>annConfFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>bratDataDir</entry>
<entry>bratDataDir</entry>
<entry>No</entry>
<entry>Location of brat data dir</entry>
</row>
<row>
<entry>recursive</entry>
<entry>value</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>sentenceDetectorModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.namefind.TokenNameFinderConverter'>

<title>TokenNameFinderConverter</title>

<para>Converts foreign data formats (evalita,ad,conll03,bionlp2004,conll02,muc6,ontonotes,brat) to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp TokenNameFinderConverter help|evalita|ad|conll03|bionlp2004|conll02|muc6|ontonotes|brat 
        [help|options...] 
]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='3' valign='middle'>evalita</entry>
<entry>lang</entry>
<entry>it</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,gpe</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>splitHyphenatedTokens</entry>
<entry>split</entry>
<entry>Yes</entry>
<entry>If true all hyphenated tokens will be separated (default true)</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll03</entry>
<entry>lang</entry>
<entry>en|de</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>bionlp2004</entry>
<entry>types</entry>
<entry>DNA,protein,cell_type,cell_line,RNA</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='3' valign='middle'>conll02</entry>
<entry>lang</entry>
<entry>es|nl</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>types</entry>
<entry>per,loc,org,misc</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='2' valign='middle'>muc6</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='5' valign='middle'>brat</entry>
<entry>tokenizerModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>ruleBasedTokenizer</entry>
<entry>name</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>annotationConfig</entry>
<entry>annConfFile</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry>bratDataDir</entry>
<entry>bratDataDir</entry>
<entry>No</entry>
<entry>Location of brat data dir</entry>
</row>
<row>
<entry>recursive</entry>
<entry>value</entry>
<entry>Yes</entry>
<entry></entry>
</row>
<row>
<entry>sentenceDetectorModel</entry>
<entry>modelFile</entry>
<entry>Yes</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.namefind.CensusDictionaryCreator'>

<title>CensusDictionaryCreator</title>

<para>Converts 1990 US Census names into a dictionary</para>

<screen>
<![CDATA[
Usage: opennlp CensusDictionaryCreator [-encoding charsetName] [-lang code] -dict dict -censusData censusDict

Arguments description:
	-encoding charsetName
	-lang code
	-dict dict
	-censusData censusDict

]]>
</screen> 
</section>

</section>

<section id='tools.cli.postag'>

<title>Postag</title>

<section id='tools.cli.postag.POSTagger'>

<title>POSTagger</title>

<para>Learnable part of speech tagger</para>

<screen>
<![CDATA[
Usage: opennlp POSTagger model < sentences

]]>
</screen> 
</section>

<section id='tools.cli.postag.POSTaggerTrainer'>

<title>POSTaggerTrainer</title>

<para>Trains a model for the part-of-speech tagger</para>

<screen>
<![CDATA[
Usage: opennlp POSTaggerTrainer[.ad|.conllx|.parse|.ontonotes] [-factory factoryName] [-type 
        maxent|perceptron|perceptron_sequence] [-dict dictionaryPath] [-ngram cutoff] [-tagDictCutoff 
        tagDictCutoff] [-params paramsFile] -lang language -model modelFile -data sampleData [-encoding 
        charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of POSTaggerFactory where to get implementation and resources.
	-type maxent|perceptron|perceptron_sequence
		The type of the token name finder model. One of maxent|perceptron|perceptron_sequence.
	-dict dictionaryPath
		The XML tag dictionary file
	-ngram cutoff
		NGram cutoff. If not specified will not create ngram dictionary.
	-tagDictCutoff tagDictCutoff
		TagDictionary cutoff. If specified will create/expand a mutable TagDictionary
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>expandME</entry>
<entry>expandME</entry>
<entry>Yes</entry>
<entry>Expand multiword expressions.</entry>
</row>
<row>
<entry>includeFeatures</entry>
<entry>includeFeatures</entry>
<entry>Yes</entry>
<entry>Combine POS Tags with word features, like number and gender.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.postag.POSTaggerEvaluator'>

<title>POSTaggerEvaluator</title>

<para>Measures the performance of the POS tagger model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp POSTaggerEvaluator[.ad|.conllx|.parse|.ontonotes] [-misclassified true|false] -model model 
        [-reportOutputFile outputFile] -data sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>expandME</entry>
<entry>expandME</entry>
<entry>Yes</entry>
<entry>Expand multiword expressions.</entry>
</row>
<row>
<entry>includeFeatures</entry>
<entry>includeFeatures</entry>
<entry>Yes</entry>
<entry>Combine POS Tags with word features, like number and gender.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.postag.POSTaggerCrossValidator'>

<title>POSTaggerCrossValidator</title>

<para>K-fold cross validator for the learnable POS tagger</para>

<screen>
<![CDATA[
Usage: opennlp POSTaggerCrossValidator[.ad|.conllx|.parse|.ontonotes] [-folds num] [-misclassified 
        true|false] [-factory factoryName] [-type maxent|perceptron|perceptron_sequence] [-dict 
        dictionaryPath] [-ngram cutoff] [-tagDictCutoff tagDictCutoff] [-params paramsFile] -lang language 
        [-reportOutputFile outputFile] -data sampleData [-encoding charsetName] 
Arguments description:
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-factory factoryName
		A sub-class of POSTaggerFactory where to get implementation and resources.
	-type maxent|perceptron|perceptron_sequence
		The type of the token name finder model. One of maxent|perceptron|perceptron_sequence.
	-dict dictionaryPath
		The XML tag dictionary file
	-ngram cutoff
		NGram cutoff. If not specified will not create ngram dictionary.
	-tagDictCutoff tagDictCutoff
		TagDictionary cutoff. If specified will create/expand a mutable TagDictionary
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>expandME</entry>
<entry>expandME</entry>
<entry>Yes</entry>
<entry>Expand multiword expressions.</entry>
</row>
<row>
<entry>includeFeatures</entry>
<entry>includeFeatures</entry>
<entry>Yes</entry>
<entry>Combine POS Tags with word features, like number and gender.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.postag.POSTaggerConverter'>

<title>POSTaggerConverter</title>

<para>Converts foreign data formats (ad,conllx,parse,ontonotes) to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp POSTaggerConverter help|ad|conllx|parse|ontonotes [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>expandME</entry>
<entry>expandME</entry>
<entry>Yes</entry>
<entry>Expand multiword expressions.</entry>
</row>
<row>
<entry>includeFeatures</entry>
<entry>includeFeatures</entry>
<entry>Yes</entry>
<entry>Combine POS Tags with word features, like number and gender.</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>conllx</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='1' valign='middle'>parse</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

</section>

<section id='tools.cli.lemmatizer'>

<title>Lemmatizer</title>

<section id='tools.cli.lemmatizer.LemmatizerME'>

<title>LemmatizerME</title>

<para>Learnable lemmatizer</para>

<screen>
<![CDATA[
Usage: opennlp LemmatizerME model < sentences

]]>
</screen> 
</section>

<section id='tools.cli.lemmatizer.LemmatizerTrainerME'>

<title>LemmatizerTrainerME</title>

<para>Trainer for the learnable lemmatizer</para>

<screen>
<![CDATA[
Usage: opennlp LemmatizerTrainerME [-factory factoryName] [-params paramsFile] -lang language -model 
        modelFile -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of LemmatizerFactory where to get implementation and resources.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.lemmatizer.LemmatizerEvaluator'>

<title>LemmatizerEvaluator</title>

<para>Measures the performance of the Lemmatizer model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp LemmatizerEvaluator [-misclassified true|false] -model model [-reportOutputFile outputFile] 
        -data sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-reportOutputFile outputFile
		the path of the fine-grained report file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
</tbody>
</tgroup></informaltable>

</section>

</section>

<section id='tools.cli.chunker'>

<title>Chunker</title>

<section id='tools.cli.chunker.ChunkerME'>

<title>ChunkerME</title>

<para>Learnable chunker</para>

<screen>
<![CDATA[
Usage: opennlp ChunkerME model < sentences

]]>
</screen> 
</section>

<section id='tools.cli.chunker.ChunkerTrainerME'>

<title>ChunkerTrainerME</title>

<para>Trainer for the learnable chunker</para>

<screen>
<![CDATA[
Usage: opennlp ChunkerTrainerME[.ad] [-factory factoryName] [-params paramsFile] -lang language -model 
        modelFile -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of ChunkerFactory where to get implementation and resources.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>start</entry>
<entry>start</entry>
<entry>Yes</entry>
<entry>Index of first sentence</entry>
</row>
<row>
<entry>end</entry>
<entry>end</entry>
<entry>Yes</entry>
<entry>Index of last sentence</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.chunker.ChunkerEvaluator'>

<title>ChunkerEvaluator</title>

<para>Measures the performance of the Chunker model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp ChunkerEvaluator[.ad] [-misclassified true|false] -model model [-detailedF true|false] -data 
        sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-detailedF true|false
		if true will print detailed FMeasure results.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>start</entry>
<entry>start</entry>
<entry>Yes</entry>
<entry>Index of first sentence</entry>
</row>
<row>
<entry>end</entry>
<entry>end</entry>
<entry>Yes</entry>
<entry>Index of last sentence</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.chunker.ChunkerCrossValidator'>

<title>ChunkerCrossValidator</title>

<para>K-fold cross validator for the chunker</para>

<screen>
<![CDATA[
Usage: opennlp ChunkerCrossValidator[.ad] [-factory factoryName] [-params paramsFile] -lang language [-folds 
        num] [-misclassified true|false] [-detailedF true|false] -data sampleData [-encoding charsetName] 
Arguments description:
	-factory factoryName
		A sub-class of ChunkerFactory where to get implementation and resources.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-folds num
		number of folds, default is 10.
	-misclassified true|false
		if true will print false negatives and false positives.
	-detailedF true|false
		if true will print detailed FMeasure results.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>start</entry>
<entry>start</entry>
<entry>Yes</entry>
<entry>Index of first sentence</entry>
</row>
<row>
<entry>end</entry>
<entry>end</entry>
<entry>Yes</entry>
<entry>Index of last sentence</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.chunker.ChunkerConverter'>

<title>ChunkerConverter</title>

<para>Converts ad data format to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp ChunkerConverter help|ad [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='4' valign='middle'>ad</entry>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>No</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
<row>
<entry>lang</entry>
<entry>language</entry>
<entry>No</entry>
<entry>Language which is being processed.</entry>
</row>
<row>
<entry>start</entry>
<entry>start</entry>
<entry>Yes</entry>
<entry>Index of first sentence</entry>
</row>
<row>
<entry>end</entry>
<entry>end</entry>
<entry>Yes</entry>
<entry>Index of last sentence</entry>
</row>
<row>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

</section>

<section id='tools.cli.parser'>

<title>Parser</title>

<section id='tools.cli.parser.Parser'>

<title>Parser</title>

<para>Performs full syntactic parsing</para>

<screen>
<![CDATA[
Usage: opennlp Parser [-bs n -ap n -k n -tk tok_model] model < sentences 
-bs n: Use a beam size of n.
-ap f: Advance outcomes in with at least f% of the probability mass.
-k n: Show the top n parses.  This will also display their log-probablities.
-tk tok_model: Use the specified tokenizer model to tokenize the sentences. Defaults to a WhitespaceTokenizer.

]]>
</screen> 
</section>

<section id='tools.cli.parser.ParserTrainer'>

<title>ParserTrainer</title>

<para>Trains the learnable parser</para>

<screen>
<![CDATA[
Usage: opennlp ParserTrainer[.ontonotes|.frenchtreebank] [-headRulesSerializerImpl className] -headRules 
        headRulesFile [-parserType CHUNKING|TREEINSERT] [-fun true|false] [-params paramsFile] -lang language 
        -model modelFile [-encoding charsetName] -data sampleData 
Arguments description:
	-headRulesSerializerImpl className
		head rules artifact serializer class name
	-headRules headRulesFile
		head rules file.
	-parserType CHUNKING|TREEINSERT
		one of CHUNKING or TREEINSERT, default is CHUNKING.
	-fun true|false
		Learn to generate function tags.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-model modelFile
		output model file.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.
	-data sampleData
		data to be used, usually a file name.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='1' valign='middle'>frenchtreebank</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.parser.ParserEvaluator'>

<title>ParserEvaluator</title>

<para>Measures the performance of the Parser model with the reference data</para>

<screen>
<![CDATA[
Usage: opennlp ParserEvaluator[.ontonotes|.frenchtreebank] [-misclassified true|false] -model model -data 
        sampleData [-encoding charsetName] 
Arguments description:
	-misclassified true|false
		if true will print false negatives and false positives.
	-model model
		the model file to be evaluated.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='1' valign='middle'>frenchtreebank</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.parser.ParserConverter'>

<title>ParserConverter</title>

<para>Converts foreign data formats (ontonotes,frenchtreebank) to native OpenNLP format</para>

<screen>
<![CDATA[
Usage: opennlp ParserConverter help|ontonotes|frenchtreebank [help|options...]

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='1' valign='middle'>frenchtreebank</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.parser.BuildModelUpdater'>

<title>BuildModelUpdater</title>

<para>Trains and updates the build model in a parser model</para>

<screen>
<![CDATA[
Usage: opennlp BuildModelUpdater[.ontonotes|.frenchtreebank] -model modelFile [-params paramsFile] -lang 
        language -data sampleData [-encoding charsetName] 
Arguments description:
	-model modelFile
		output model file.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='1' valign='middle'>frenchtreebank</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.parser.CheckModelUpdater'>

<title>CheckModelUpdater</title>

<para>Trains and updates the check model in a parser model</para>

<screen>
<![CDATA[
Usage: opennlp CheckModelUpdater[.ontonotes|.frenchtreebank] -model modelFile [-params paramsFile] -lang 
        language -data sampleData [-encoding charsetName] 
Arguments description:
	-model modelFile
		output model file.
	-params paramsFile
		training parameters file.
	-lang language
		language which is being processed.
	-data sampleData
		data to be used, usually a file name.
	-encoding charsetName
		encoding for reading and writing text, if absent the system default is used.

]]>
</screen> 
<para>The supported formats and arguments are:</para>

<informaltable frame='all'><tgroup cols='4' align='left' colsep='1' rowsep='1'>
<thead><row><entry>Format</entry><entry>Argument</entry><entry>Value</entry><entry>Optional</entry><entry>Description</entry></row></thead>
<tbody>
<row>
<entry morerows='0' valign='middle'>ontonotes</entry>
<entry>ontoNotesDir</entry>
<entry>OntoNotes 4.0 corpus directory</entry>
<entry>No</entry>
<entry></entry>
</row>
<row>
<entry morerows='1' valign='middle'>frenchtreebank</entry>
<entry>data</entry>
<entry>sampleData</entry>
<entry>No</entry>
<entry>Data to be used, usually a file name.</entry>
</row>
<row>
<entry>encoding</entry>
<entry>charsetName</entry>
<entry>Yes</entry>
<entry>Encoding for reading and writing text, if absent the system default is used.</entry>
</row>
</tbody>
</tgroup></informaltable>

</section>

<section id='tools.cli.parser.TaggerModelReplacer'>

<title>TaggerModelReplacer</title>

<para>Replaces the tagger model in a parser model</para>

<screen>
<![CDATA[
Usage: opennlp TaggerModelReplacer parser.model tagger.model

]]>
</screen> 
</section>

</section>

<section id='tools.cli.entitylinker'>

<title>Entitylinker</title>

<section id='tools.cli.entitylinker.EntityLinker'>

<title>EntityLinker</title>

<para>Links an entity to an external data set</para>

<screen>
<![CDATA[
Usage: opennlp EntityLinker model < sentences

]]>
</screen> 
</section>

</section>

<section id='tools.cli.languagemodel'>

<title>Languagemodel</title>

<section id='tools.cli.languagemodel.LanguageModel'>

<title>LanguageModel</title>

<para>Gives the probability of a sequence of tokens in a language model</para>

<screen>
<![CDATA[
Usage: opennlp LanguageModel model

]]>
</screen> 
</section>

</section>



</chapter>
